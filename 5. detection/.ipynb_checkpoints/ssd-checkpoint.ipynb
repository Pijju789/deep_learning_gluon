{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import init, gluon, nd, autograd, image, metric\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.contrib.ndarray import MultiBoxPrior, MultiBoxTarget, MultiBoxDetection\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi']= 120\n",
    "ctx = mx.cpu()\n",
    "data_dir = '/Users/air/python/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size, data_route = data_dir):\n",
    "    root_url = ('https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/pikachu/')\n",
    "    data_dir = data_route+'/pikachu/'\n",
    "    dataset = {'train.rec': 'e6bcb6ffba1ac04ff8a9b1115e650af56ee969c8',\n",
    "              'train.idx': 'dcf7318b2602c06428b9988470c731621716c393',\n",
    "              'val.rec': 'd6c33f799b4d058e82f2cb5bd9a976f69d72d520'}\n",
    "    for k, v in dataset.items():\n",
    "        gluon.utils.download(root_url+k, data_dir+k, sha1_hash=v)\n",
    "    \n",
    "    train_iter = image.ImageDetIter(\n",
    "        batch_size = batch_size, data_shape = (3, 256, 256),\n",
    "        path_imgrec = data_dir+'train.rec', path_imgidx = data_dir+'train.idx',\n",
    "        shuffle = True, mean = True, rand_crop = 1,\n",
    "        min_object_covered = 0.95, max_attempts = 200)\n",
    "    val_iter = image.ImageDetIter(\n",
    "        batch_size = batch_size, data_shape = (3, 256, 256),\n",
    "        path_imgrec=data_dir+'val.rec', shuffle=False, mean=True)\n",
    "    return train_iter, val_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "class_names = ['pikachu']\n",
    "num_class = len(class_names)\n",
    "\n",
    "train_data, test_data = load_data(batch_size)\n",
    "train_data.reshape(label_shape=(3, 5))\n",
    "train_data = test_data.sync_label_shape(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_predictor(num_anchors, num_classes):\n",
    "    return nn.Conv2D(num_anchors * (num_classes + 1), 3, padding=1)\n",
    "\n",
    "def box_predictor(num_anchors):\n",
    "    return nn.Conv2D(num_anchors * 4, 3, padding=1)\n",
    "\n",
    "def down_sample(num_filters):\n",
    "    out = nn.HybridSequential()\n",
    "    for _ in range(2):\n",
    "        out.add(nn.Conv2D(num_filters, 3, strides=1, padding=1))\n",
    "        out.add(nn.BatchNorm(in_channels=num_filters))\n",
    "        out.add(nn.Activation('relu'))\n",
    "    out.add(nn.MaxPool2D(2))\n",
    "    return out\n",
    "\n",
    "def flatten_prediction(pred):\n",
    "    return pred.transpose(axes=(0,2,3,1)).flatten()\n",
    "\n",
    "def concat_predictions(preds):\n",
    "    return nd.concat(*preds, dim=1)\n",
    "\n",
    "def body():\n",
    "    out = nn.HybridSequential()\n",
    "    for nfilters in [16, 32, 64]:\n",
    "        out.add(down_sample(nfilters))\n",
    "    return out\n",
    "\n",
    "def toy_ssd_model(num_anchors, num_classes):\n",
    "    downsamplers = nn.Sequential()\n",
    "    for _ in range(3):\n",
    "        downsamplers.add(down_sample(128))\n",
    "    class_predictors = nn.Sequential()\n",
    "    box_predictors = nn.Sequential()    \n",
    "    for _ in range(5):\n",
    "        class_predictors.add(class_predictor(num_anchors, num_classes))\n",
    "        box_predictors.add(box_predictor(num_anchors))\n",
    "    model = nn.Sequential()\n",
    "    model.add(body(), downsamplers, class_predictors, box_predictors)\n",
    "    return model\n",
    "\n",
    "def toy_ssd_forward(x, model, sizes, ratios):    \n",
    "    body, downsamplers, class_predictors, box_predictors = model\n",
    "    anchors, class_preds, box_preds = [], [], []\n",
    "    x = body(x)\n",
    "    for i in range(5):\n",
    "        anchors.append(MultiBoxPrior(x, sizes=sizes[i], ratios=ratios[i]))\n",
    "        class_preds.append(flatten_prediction(class_predictors[i](x)))\n",
    "        box_preds.append(flatten_prediction(box_predictors[i](x)))\n",
    "        if i < 3:\n",
    "            x = downsamplers[i](x)\n",
    "        elif i == 3:\n",
    "            x = nd.Pooling(x, global_pool=True, pool_type='max', \n",
    "                           kernel=(x.shape[2], x.shape[3]))\n",
    "    return (concat_predictions(anchors), \n",
    "            concat_predictions(class_preds), \n",
    "            concat_predictions(box_preds))\n",
    "\n",
    "def training_targets(anchors, class_preds, labels):\n",
    "    class_preds = class_preds.transpose(axes=(0,2,1))\n",
    "    return MultiBoxTarget(anchors, labels, class_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToySSD(gluon.Block):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(ToySSD, self).__init__(**kwargs)\n",
    "        self.sizes = [[.2,.272], [.37,.447], [.54,.619], [.71,.79], [.88,.961]]\n",
    "        self.ratios = [[1,2,.5]]*5\n",
    "        self.num_classes = num_classes\n",
    "        num_anchors = len(self.sizes[0]) + len(self.ratios[0]) - 1\n",
    "        with self.name_scope():\n",
    "            self.model = toy_ssd_model(num_anchors, num_classes)\n",
    "    def forward(self, x):\n",
    "        anchors, class_preds, box_preds = toy_ssd_forward(\n",
    "            x, self.model, self.sizes, self.ratios)  \n",
    "        class_preds = class_preds.reshape(shape=(0, -1, self.num_classes+1))\n",
    "        return anchors, class_preds, box_preds\n",
    "\n",
    "class FocalLoss(gluon.loss.Loss):\n",
    "    def __init__(self, axis=-1, alpha=0.25, gamma=2, batch_axis=0, **kwargs):\n",
    "        super(FocalLoss, self).__init__(None, batch_axis, **kwargs)\n",
    "        self._axis = axis\n",
    "        self._alpha = alpha\n",
    "        self._gamma = gamma\n",
    "    def hybrid_forward(self, F, output, label):\n",
    "        output = F.softmax(output)\n",
    "        pj = output.pick(label, axis=self._axis, keepdims=True)\n",
    "        loss = - self._alpha * ((1 - pj) ** self._gamma) * pj.log()\n",
    "        return loss.mean(axis=self._batch_axis, exclude=True)\n",
    "    \n",
    "class SmoothL1Loss(gluon.loss.Loss):\n",
    "    def __init__(self, batch_axis=0, **kwargs):\n",
    "        super(SmoothL1Loss, self).__init__(None, batch_axis, **kwargs)\n",
    "    def hybrid_forward(self, F, output, label, mask):\n",
    "        loss = F.smooth_l1((output - label) * mask, scalar=1.0)\n",
    "        return loss.mean(self._batch_axis, exclude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_loss = FocalLoss()\n",
    "box_loss = SmoothL1Loss()\n",
    "\n",
    "net = ToySSD(num_class)\n",
    "net.initialize(init.Xavier(magnitude=2), ctx=ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1, 'wd': 5e-4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    start = time()\n",
    "    train_data.reset()\n",
    "    for i, batch in enumerate(train_data):\n",
    "        x = batch.data[0].as_in_context(ctx)\n",
    "        y = batch.label[0].as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            anchors, class_preds, box_preds = net(x)\n",
    "            box_target, box_mask, cls_target = training_targets(anchors, class_preds, y)\n",
    "            loss1 = cls_loss(class_preds, cls_target)\n",
    "            loss2 = box_loss(box_preds, box_target, box_mask)\n",
    "            loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "    if epoch%1 == 0:\n",
    "        print('%d, loss %.4f, t %.4f' % (epoch, nd.mean(loss).asscalar(), time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(fname):\n",
    "    rgb_mean = nd.array([123, 117, 104])\n",
    "    with open(fname, 'rb') as f:\n",
    "        im = image.imdecode(f.read())\n",
    "    data = image.imresize(im, data_shape, data_shape)\n",
    "    data = data.astype('float32') - rgb_mean\n",
    "    return data.transpose((2,0,1)).expand_dims(axis=0), im\n",
    "\n",
    "def predict(x):\n",
    "    anchors, cls_preds, box_preds = net(x.as_in_context(ctx))\n",
    "    cls_probs = nd.SoftmaxActivation(cls_preds.transpose((0,2,1)), mode='channel')\n",
    "    return MultiBoxDetection(cls_probs, box_preds, anchors,force_suppress=True, clip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, im = process_image('pikachu.jpg')\n",
    "out = predict(x)\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'black', 'magenta']\n",
    "\n",
    "def box_to_rect(box, color, linewidth=3):\n",
    "    box = box.asnumpy()\n",
    "    return plt.Rectangle(\n",
    "        (box[0], box[1]), box[2]-box[0], box[3]-box[1],\n",
    "        fill=False, edgecolor=color, linewidth=linewidth)\n",
    "\n",
    "def display(im, out, threshold=0.5):    \n",
    "    plt.imshow(im.asnumpy())\n",
    "    for row in out:\n",
    "        row = row.asnumpy()\n",
    "        class_id, score = int(row[0]), row[1]\n",
    "        if class_id < 0 or score < threshold:\n",
    "            continue\n",
    "        color = colors[class_id%len(colors)]\n",
    "        box = row[2:6] * np.array([im.shape[0],im.shape[1]]*2)\n",
    "        rect = box_to_rect(nd.array(box), color, 2)\n",
    "        plt.gca().add_patch(rect)\n",
    "        text = class_names[class_id]\n",
    "        plt.gca().text(box[0], box[1], '{:s} {:.2f}'.format(text, score),\n",
    "                       bbox=dict(facecolor=color, alpha=0.5), fontsize=10, color='white')\n",
    "    plt.show()\n",
    "\n",
    "display(im, out[0], threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
