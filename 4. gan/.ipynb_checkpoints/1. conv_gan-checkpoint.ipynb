{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, autograd\n",
    "from mxnet.gluon import nn, utils\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "ctx = mx.cpu()\n",
    "data_dir = '/Users/air/python/data/gan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():  \n",
    "    lfw_url = 'http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz'\n",
    "    data_path = data_dir + '/lfw_dataset'\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "        data_file = utils.download(lfw_url)\n",
    "        with tarfile.open(data_file) as tar:\n",
    "            tar.extractall(path=data_path)\n",
    "    img_list = []\n",
    "    for path, _, fnames in os.walk(data_path):\n",
    "        for fname in fnames:\n",
    "            if not fname.endswith('.jpg'):\n",
    "                continue\n",
    "            img = os.path.join(path, fname)\n",
    "            img_arr = mx.image.imread(img)\n",
    "            img_arr = transform(img_arr)\n",
    "            img_list.append(img_arr)\n",
    "    train_data = mx.io.NDArrayIter(data=nd.concatenate(img_list), batch_size=batch_size)\n",
    "    return train_data\n",
    "\n",
    "def transform(data):\n",
    "    data = mx.image.imresize(data, 64, 64)\n",
    "    data = nd.transpose(data, (2,0,1))\n",
    "    data = data.astype(np.float32)/127.5 - 1\n",
    "    if data.shape[0] == 1:\n",
    "        data = nd.tile(data, (3, 1, 1))\n",
    "    return data.reshape((1,) + data.shape)\n",
    "\n",
    "def visualize(img_arr):\n",
    "    plt.imshow(((img_arr.asnumpy().transpose(1, 2, 0) + 1.0) * 127.5).astype(np.uint8))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_data = load_data()\n",
    "real_label = nd.ones((batch_size,), ctx=ctx)\n",
    "fake_label = nd.zeros((batch_size,), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = nn.Sequential()\n",
    "with netG.name_scope():\n",
    "    netG.add(nn.Conv2DTranspose(512, 4, 1, 0, use_bias=False))\n",
    "    netG.add(nn.BatchNorm())\n",
    "    netG.add(nn.Activation('relu'))\n",
    "    netG.add(nn.Conv2DTranspose(256, 4, 2, 1, use_bias=False))\n",
    "    netG.add(nn.BatchNorm())\n",
    "    netG.add(nn.Activation('relu'))\n",
    "    netG.add(nn.Conv2DTranspose(128, 4, 2, 1, use_bias=False))\n",
    "    netG.add(nn.BatchNorm())\n",
    "    netG.add(nn.Activation('relu'))\n",
    "    netG.add(nn.Conv2DTranspose(64, 4, 2, 1, use_bias=False))\n",
    "    netG.add(nn.BatchNorm())\n",
    "    netG.add(nn.Activation('relu'))\n",
    "    netG.add(nn.Conv2DTranspose(3, 4, 2, 1, use_bias=False))\n",
    "    netG.add(nn.Activation('tanh'))\n",
    "\n",
    "netD = nn.Sequential()\n",
    "with netD.name_scope():\n",
    "    netD.add(nn.Conv2D(64, 4, 2, 1, use_bias=False))\n",
    "    netD.add(nn.LeakyReLU(0.2))\n",
    "    netD.add(nn.Conv2D(128, 4, 2, 1, use_bias=False))\n",
    "    netD.add(nn.BatchNorm())\n",
    "    netD.add(nn.LeakyReLU(0.2))\n",
    "    netD.add(nn.Conv2D(256, 4, 2, 1, use_bias=False))\n",
    "    netD.add(nn.BatchNorm())\n",
    "    netD.add(nn.LeakyReLU(0.2))\n",
    "    netD.add(nn.Conv2D(512, 4, 2, 1, use_bias=False))\n",
    "    netD.add(nn.BatchNorm())\n",
    "    netD.add(nn.LeakyReLU(0.2))\n",
    "    netD.add(nn.Conv2D(1, 4, 1, 0, use_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "\n",
    "netG.initialize(mx.init.Normal(0.02), ctx=ctx)\n",
    "netD.initialize(mx.init.Normal(0.02), ctx=ctx)\n",
    "\n",
    "trainerG = gluon.Trainer(netG.collect_params(), 'adam', {'learning_rate': 2e-4, 'beta1': 0.5})\n",
    "trainerD = gluon.Trainer(netD.collect_params(), 'adam', {'learning_rate': 2e-4, 'beta1': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time()\n",
    "    train_data.reset()\n",
    "    for batch in train_data:\n",
    "        data = batch.data[0].as_in_context(ctx)\n",
    "        latent_z = nd.random_normal(0, 1, shape=(batch_size, 100, 1, 1), ctx=ctx)\n",
    "        with autograd.record():\n",
    "            output = netD(data).reshape((-1, 1))\n",
    "            errD_real = loss(output, real_label)\n",
    "            fake = netG(latent_z)\n",
    "            output = netD(fake.detach()).reshape((-1, 1))\n",
    "            errD_fake = loss(output, fake_label)\n",
    "            errD = errD_real + errD_fake\n",
    "            errD.backward()\n",
    "        trainerD.step(batch.data[0].shape[0])\n",
    "        with autograd.record():\n",
    "            fake = netG(latent_z)\n",
    "            output = netD(fake).reshape((-1, 1))\n",
    "            errG = loss(output, real_label)\n",
    "            errG.backward()\n",
    "        trainerG.step(batch.data[0].shape[0])\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "        print('%d, dloss %.4f, gloss %.4f, T %.4f' %(\n",
    "            epoch, nd.mean(errD).asscalar(), nd.mean(errG).asscalar(), time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image = 8\n",
    "\n",
    "for i in range(num_image):\n",
    "    latent_z = nd.random_normal(0, 1, shape=(1, 100, 1, 1), ctx=ctx)\n",
    "    img = netG(latent_z)\n",
    "    plt.subplot(2,4,i+1)\n",
    "    visualize(img[0])\n",
    "plt.show()w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
